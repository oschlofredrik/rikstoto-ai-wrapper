# Rikstoto AI Wrapper - Environment Variables
# Kopier denne filen til .env og fyll inn dine egne verdier

# === Azure OpenAI Configuration ===
# For GPT-4o, GPT-4o-mini og o3-mini
AZURE_OPENAI_API_KEY=your-azure-openai-api-key-here
AZURE_OPENAI_ENDPOINT=https://your-resource-name.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# Deployment names for each model (optional - defaults to model name)
AZURE_OPENAI_GPT4O_DEPLOYMENT=gpt-4o
AZURE_OPENAI_GPT4O_MINI_DEPLOYMENT=gpt-4o-mini
AZURE_OPENAI_O3_MINI_DEPLOYMENT=o3-mini

# === Mistral Large Configuration ===
# Azure AI Model-as-a-Service
AZURE_MISTRAL_ENDPOINT=https://your-mistral-endpoint.models.ai.azure.com
AZURE_MISTRAL_API_KEY=your-mistral-api-key-here

# === Claude 3.5 Sonnet Configuration ===
# Option 1: Via Azure Databricks
AZURE_DATABRICKS_CLAUDE_ENDPOINT=https://your-databricks-endpoint.azuredatabricks.net/serving-endpoints/claude
AZURE_DATABRICKS_API_KEY=your-databricks-api-key-here

# Option 2: Direct Anthropic API (fallback)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# === Gemini 1.5 Flash Configuration ===
# Option 1: Via Azure API Management
AZURE_APIM_GEMINI_ENDPOINT=https://your-apim-instance.azure-api.net/gemini
AZURE_APIM_GEMINI_KEY=your-apim-subscription-key-here

# Option 2: Direct Google API (fallback)
GOOGLE_API_KEY=your-google-api-key-here

# === Legacy Hugging Face Configuration ===
# Kept for compatibility with other models
HUGGINGFACE_TOKEN=your-huggingface-token-here
INFERENCE_ENDPOINT_URL=https://your-endpoint.aws.endpoints.huggingface.cloud

# === Application Configuration ===
ENVIRONMENT=development
HF_HOME=./cache/huggingface
TRANSFORMERS_CACHE=./cache/huggingface

# === CORS Configuration (for local development) ===
# Update for production deployment
CORS_ORIGINS=["http://localhost:3001"]